import scrapy
from khinfo.items import *
from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors import LinkExtractor

class KhinfoSpider(CrawlSpider):
    name = "khinfospider"
    allowed_domains = ["www.kharkov.info"]
    start_urls = [
        "http://www.kharkov.info/place/bytovye-uslugi",
        "http://www.kharkov.info/place/razvlecheniya"]
        
    rules = (
        Rule(LinkExtractor(allow=['\?page=\d+'],), callback='collect_urls'),
        Rule(LinkExtractor(allow=['/place/\d+'],), callback='parse_it'),
        )

    def collect_urls(self, response):
        self.start_urls.append(responce.url)


    def parse_it(self, response):
        service = KhinfoItem()
        service['url'] = response.url
        service['category'] = response.xpath("//div[@class='catalog']//a/text()").extract()
        service['summary'] = response.xpath("//div[@class='place-title']/h1/text()").extract()
        service['description'] = response.xpath("//div[@id='about']//*/text()").extract()
        service['phone'] = response.xpath("//div[@class='phone_field']//*/text()").extract()
        service['website_url'] = response.xpath("//div[@class='site_field']//a/text()").extract()
        return service
