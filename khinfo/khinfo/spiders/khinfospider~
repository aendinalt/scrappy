import scrapy
from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors import LinkExtractor

class KhinfoSpider(scrapy.Spider):
    name = "khinfo"
    allowed_domains = ["kharkov.info"]
    start_urls = [
        "http://www.kharkov.info/place/"
    ]
    rules = [Rule(LinkExtractor(allow=['\d+']), 'parse')]

    def parse(self, response):
        service = KhinfoItem()
        service['url'] = response.url
        service['category'] = responce.xpath("//div[@class='catalog']//a/text()").extract()
        service['summary'] = responce.xpath("//div[@class='place-title']/h1/text()").extract()
        service['description'] = responce.xpath("//div[@id='about']//*/text()").extract()
        service['phone'] = responce.xpath("//div[@class='phone_field']//*/text()").extract()
        service['website_url'] = responce.xpath("//div[@class='site_field']//a/text()").extract()
        return service
